\section{Elección de una red neuronal}
Para la elección de la red neuronal se tomará en cuenta un estudio realizado por el equipo de YOLO (\cite{persona}), este equipo realizo pruebas con diferentes redes neuronales, para poder demostrar el gran rendimiento que tiene la red YOLO, estas pruebas fueron hechas en la misma computadora, el resultado de estas pruebas se puede observar en la Figura \ref{fig:labeling3} que da como ganador la red neuronal YOLO.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{imagenes/persona9.png}
	\caption{Comparación de YOLO y otros detectores de objetos de última generación.}
	\source{YOLOv4: Optimal Speed and Accuracy of Object Detection. (2020)}
	\label{fig:labeling3}
\end{figure}

Estas pruebas fueron realizadas haciendo el uso de la base de datos \say{coco}, que recopila una gran base de datos que facilitan la detección de diferentes objetos. Con estos resultados nos muestran que la red neuronal YOLO es la mejor opción, ya que detecta los objetos con mayor velocidad y con un mayor porcentaje de acierto. 

\section{Entrenamiento de la red neuronal}
En este capítulo se desarrollarán los diferentes pasos para lograr entrenar una red neuronal, para que sea capaz de detectar personas ya ser en imágenes o en videos tanto grabados como en tiempo real.

 \subsection{Base de datos}
Uno de los primeros pasos para entrenar una red neuronal es tener una base de datos, la cual está compuesta por imágenes (donde aparezca el objeto a detectar) y un archivo que indique la posición del objeto a detectar en la imagen.
\\ Para ello se consiguió 400 imágenes donde aparezcan personas y con ellos realizar un procedimiento de etiquetado, en la Figura \ref{fig:labeling} se observa este proceso. Esto se logra mediante el programa LabelImg que te permite etiquetar la posición de una persona en una imagen.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.25]{imagenes/persona1.png}
	\caption{Proceso de etiquetado para generar los archivos necesarios para el entrenamiento.}
	\source{Elaboración propia}
	\label{fig:labeling}
\end{figure}

Este proceso se realiza con cada imagen, para así obtener un archivo que especifica la posición de dónde se encuentra la \say{persona} en este caso. En la Figura \ref{fig:labeling2} se observa la manera en la que se guardan esos datos. 

\clearpage

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{imagenes/persona2.png}
	\caption{Coordenadas obtenidas por el programa LabelImg al etiquetar a un objeto.}
	\source{Elaboración propia}
	\label{fig:labeling2}
\end{figure}

Esta recopilación de datos se puede realizar más fácil gracias a Google, facilitando esta tarea permitiéndote usar su propia base de datos donde aproximadamente tiene cuatro millones de imágenes, Figura \ref{fig:labeling5}, el cual ya fueron etiquetados varios objetos como ser personas, autos, aviones, relojes y otros más.



\begin{figure}[h]
	\centering
	\includegraphics[scale=0.2]{imagenes/persona5.png}
	\caption{Base de datos de Google para el entrenamiento de redes neuronales.}
	\source{Elaboración propia}
	\label{fig:labeling5}
	\end{figure}

\subsection{Preparación del ambiente}

Para entrenar una red neuronal se necesita muchos recursos en una computadora sobre todo en el área del GPU, ya que todos los cálculos que realiza son procesados de manera más efectiva en esa área. 
Por ese motivo se decidió usar un servicio de Google que es Colab, el cual te permite conectarse a sus servidores y poder entrenar la red de forma gratuita. 
\\

Colab es un editor de texto online, que te permite escribir tu código y probarlo sin la necesidad de instalar programas en tu computadora, pero será necesarios instalarlos en tu editor online. El primer paso es instalar Darknet, el cual te permite trabajar con YOLO.

\clearpage

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona3.png}
	\caption{Frameworks necesarios para que funcione Darknet.}
	\source{Elaboración propia}
	\label{fig:labeling42}
\end{figure}

 Como se observa en la Figura \ref{fig:labeling42}, Darknet necesita diferentes frameworks para que funcione. Estos se instalan con la ayuda del comando \textit{pip}, el cual es un sistema de gestión de paquetes de Python. Se procederá a instalar estos paquetes mediante el comando que se aprecia en la Figura \ref{fig:labeling43}, ya que estos requisitos están guardados en un archivo \say{.txt} en el mismo Darknet.
 
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona4.png}
	\caption{Comando de instalación de paquetes.}
	\source{Elaboración propia}
	\label{fig:labeling43}
\end{figure}


\subsection{Personalizar una red neuronal}

En esta etapa, se debe modificar diferentes archivos para que la red pueda detectar a personas. Estos archivos por modificar son los parámetros que definen la red neuronal, en Darknet existen 2 redes principales que son Yolo y Tiny-Yolo. La gran diferencia entre estos son la cantidad de capas que poseen, esto llega a afectar el rendimiento en una detección. 
\vspace{5mm}

Por eso mismo se decidió usar Tiny-Yolo, ya que con pruebas realizadas dio un mejor rendimiento en el apartado de frames por segundo (fps), al momento de trabajar con videos, esto es muy importante porque la detección se realizará en tiempo real. Los resultados de la prueba se apreciará mejor en la Tabla \ref{tab:fruta}.

\clearpage

\begin{table}[t]
\caption{Resultados de una prueba de rendimiento entre YOLO y Tyni-Yolo.}
\begin{center}
%\caption{Resultados de una prueba de rendimiento entre YOLO y Tyni-Yolo.}
\begin{tabular}{| r | l |}
\hline \textbf{Versión de YOLO} & \textbf{FPS} \\ \hline
Tiny-yolo & 7-10  \\
Yolo & 1-3 \\ \hline
\end{tabular}

\label{tab:fruta}
\source{Elaboración propia.}
\end{center}
\end{table}

Con estos resultados se modificará el archivo \say{yolov4-tiny.cfg}, y los datos a cambiar dependerán mayormente a la cantidad de clases al cual se entrenara la red neuronal, estos datos son los que están marcados en la Figura \ref{fig:labeling6}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona6.png}
	\caption{Se define el learning rate.}
	\source{Elaboración propia}
	\label{fig:labeling6}
\end{figure}

El dato marcado \textit{learning rate} es el que determina el ritmo de aprendizaje, este dato entre más bajo podría aprender más, pero  eso alarga el periodo de entrenamiento y aumenta la probabilidad de que se detenga el entrenamiento por un error, en este apartado no hay que exagerar porque un dato muy bajo simplemente lo hará más lento y no ayudara en el entrenamiento, ya que ni se podría realizar.

El siguiente es \textit{max batches}, el que se encarga de limitar el número de pasos máximos que realizará en el entrenamiento. Este número es obtenido mediante una simple fórmula que se observa en la Ecuación \ref{eq:maxb}, pero solo es aplicada cuando se trabajará con 3 o más clases de detección, caso contrario simplemente se tendrá que colocar \say{6000}. En \textit{step} se tomará el 80\% y 90\% de \say{max batches} respectivamente.

\begin{equation}
\label{eq:maxb}
	max\_batches = \#\operatorname{clases} * 2000
\end{equation}

Los otros datos por modificar son los que se aprecian en la Figura \ref{fig:labeling7}, que consiste la cantidad de filtros y especificar cuántas clases tendrá que aprender la red neuronal.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona7.png}
	\caption{Se establece la cantidad de filtros a usarse.}
	\source{Elaboración propia}
	\label{fig:labeling7}
\end{figure}

Para calcular la cantidad de filtros se hará uso de una fórmula simple que se puede apreciar en la Ecuación \ref{eq:clases}, este dato obtenido se tendrá cambiar en todos los filtros que se encuentra en el documento \say{yolov4-tiny.cfg}.

\begin{equation}
	filtros = (\#\operatorname{clases}+5)*3
	\label{eq:clases}
\end{equation}

Con eso finaliza los cambios en el archivo \say{yolov4-tiny.cfg}, pero aún falta editar otros 2 archivos más el cual uno definirá el nombre de la clase y en el otro se definirán la ubicación de los archivos necesarios para entrenar, la locación de donde se guardara la red entrenada y cuantas clases se usara para entrenar, esto se aprecia en la Figura \ref{fig:labeling45}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona8.png}
	\caption{Se detalla la cantidad de clases y nombres que se usarán para entrenar la red neuronal.}
	\source{Elaboración propia}
	\label{fig:labeling45}
\end{figure}

\subsection{Inicio de entrenamiento}

Para esta etapa, una vez concluido con todas las actividades necesarias para iniciar el entrenamiento dentro del ambiente de Google Colab, el cual facilita este procedimiento. Se procede a ejecutar los siguientes scripts que aparecen en la Figura \ref{fig:labeling46}, el cual creará unos archivos basados con la cantidad de clases por el cual vamos a entrenar y la cantidad de imágenes con el cual entrenara.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona11.png}
	\caption{Comando para generar archivos que guiaran el entrenamiento.}
	\source{Elaboración propia}
	\label{fig:labeling46}
\end{figure}

Con los archivos generados por el anterior comando, ya se tendría todo lo necesario para iniciar el entrenamiento. Para comenzar con este proceso solo hace falta ejecutar el siguiente comando que aparece en la Figura \ref{fig:labeling47}. La duración de este entrenamiento dependerá de la cantidad de imágenes que se usará, en este caso el entrenamiento duro aproximadamente 4 horas.
\clearpage
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona12.png}
	\caption{Comando para iniciar el entrenamiento.}
	\source{Elaboración propia}
	\label{fig:labeling47}
\end{figure}

Al finalizar el entrenamiento ya se tendrá una red neuronal funcional, capaz de detectar personas. Un resultado del entrenamiento se observa en la Figura \ref{fig:labeling48}, donde se ven marcadas una cantidad aceptable de personas que aparecen en la imagen.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona14.png}
	\caption{Resultado del entrenamiento realizado.}
	\source{Elaboración propia}
	\label{fig:labeling48}
\end{figure}

\section{Diseño de la interfaz}
Para el desarrollo de interfaces se utilizó la herramienta Balsamiq Wireframes, con el cual se diseñó 2 pantallas principales, los cuales son: detección de personas y ventana de alarma. 

\subsection{Detección de personas}

Esta es la pantalla principal de la aplicación, en el cual se observa las detecciones que se está realizando, el límite de detección y la cantidad de personas que aparecen en el video, esto se apreciará mejor en la Figura \ref{fig:labeling30}.
\clearpage
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{imagenes/imagen1.png}
	\caption{Pantalla principal de la aplicación NeoVision.}
	\source{Elaboración propia}
	\label{fig:labeling30}
\end{figure}

\subsection{Pantalla de alerta}

Esta pantalla solo aparecerá cuando la alarma se active, lo que significa, que solo saldrá en ciertas ocaciones cuando se llega a sobrepasar el tiempo máximo de espera de una persona en la fila, el diseño de esta pantalla se puede ver en la Figura \ref{fig:labeling31}.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/imagen2.png}
	\caption{Mockup de la pantalla de alerta.}
	\source{Elaboración propia}
	\label{fig:labeling31}
\end{figure}

\section{Diagrama de flujo}
En este apartado se mostrará un diagrama de flujo en el que se representa los principales procesos de este proyecto, cuáles son detectar a personas y dependiendo del tiempo de espera notificar con una alerta, este diagrama se observa en la Figura \ref{fig:labeling33}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{imagenes/NeoVision3.png}
	\caption{Diagrama de flujo explicativo sobre la función de la aplicación NeoVision.}
	\source{Elaboración propia}
	\label{fig:labeling33}
\end{figure}

\section{Diagrama C4Model}
En este apartado se dará conocer un esquema siguiendo el modelo C4Model, el cual se va explicando de manera general hasta llegar a lo más específico, empezando por el contexto de la situación, sus contenedores, componentes y por último un diagrama de todas las clases.
\clearpage
\subsection{Contexto}
En este apartado se observará las diferentes interacciones que tiene la aplicación, esto se apreciará mejor en la Figura \ref{fig:labeling32}.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/contenido2.png}
	\caption{Diagrama de contexto que representa las interacciones del sistema.}
	\source{Elaboración propia}
	\label{fig:labeling32}
\end{figure}
Con este diagrama se puede mostrar cuáles son las interacciones que realiza la aplicación, como ser el personal de sistemas es el que inicia la aplicación y si es necesario configura ciertos parámetros, por otra parte, la aplicación interactúa con el personal de seguridad mediante avisos que ejecutara cuando el tiempo de espera de una persona sobrepase el tiempo configurado.
\subsection{Contenedores}

En esta sección se observa más a detalle los sistemas usados para que la aplicación funcione, esto se ve en la Figura \ref{fig:labeling34}.
\clearpage
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/contenedor3.png}
	\caption{Diagrama de contenedores que representa las diferentes funciones de los sistemas.}
	\source{Elaboración propia}
	\label{fig:labeling34}
\end{figure}

Con este diagrama conocemos cuáles son las funciones de los diferentes sistemas que tiene la aplicación, por ejemplo, Darknet es el encargado de realizar las detecciones en las imágenes que le envía la aplicación principal. Por otra parte, Deepsort es el que recibe los resultados de Darknet y este aplica un ID único a cada detección, esta información es recibida por NeoVision, la cual le permite realizar los cálculos para determinar si es necesario abrir una nueva caja. 

\section{Descripción de la aplicación}



Para comenzar el desarrollo de la aplicación primeramente se tiene que crear una ambiente virtual de Python en la computadora, ya que se necesita instalar ciertos paquetes que podrían entrar en conflicto con algunas aplicaciones ya instaladas y también genera un mayor orden.
La herramienta ideal para realizar esto es VirtualenvWrapper, ya que es fácil de instalar y sobre todo es simple de ingresar al ambiente virtual, sobre todo cuando se compara con otras herramientas. Esta diferencia aprecia mejor en la Figura \ref{fig:labeling9}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona15.png}
	\caption{Diferencia entre iniciar un ambiente virtual de Python entre VirtualWrapper y Virtualenv.}
	\source{Elaboración propia}
	\label{fig:labeling9}
\end{figure}

\clearpage

Con el ambiente virtual se procede a instalar los diversos paquetes necesarios, donde los principales son Tensorflow y OpenCV. Teniendo estos recursos instalados, se tendrá que convertir la red neuronal entrenada a un formato que Tensorflow soporte. Para ello usaremos un código disponible hecho por la misma comunidad, que está hecho en Python, en la Figura \ref{fig:labeling10} se muestra el comando para convertir la red.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona16.png}
	\caption{Comando para convertir la red neuronal.}
	\source{Elaboración propia}
	\label{fig:labeling10}
\end{figure}

 Para realizar la aplicación se hará uso del editor PyCharm, porque es gratis y tiene una interfaz intuitiva al momento de usarlo.
 El primer paso al comenzar la aplicación es comenzar a importar todos los paquetes que se necesitará para que funcione, la manera en la que se importa los paquetes se podrá observar en el siguiente Código \ref{23}.
\begin{lstlisting}[language=Python,caption={Manera en la que se importan los diferentes paquetes al programa.},captionpos=b,label=23]
	import os 
	import subprocess
	from datatime import datetime
	import tensorflow as tf
	import time
\end{lstlisting}

Con todo esto ya se puede dar comienzo para que la aplicación pueda leer los videos mediante OpenCV y así iniciar el detector para que encuentre las personas de un video.

\subsection{Agregar el tracker a la detección}

Por sí solas la detección que se puede hacer no brinda la información suficiente como para contar las detecciones o corregir errores que se pueden generar. Uno de estos errores es que como en un video hay objetos en movimiento simplemente puede desaparecer las detecciones, debido a que por el movimiento no se llega a reconocer al objeto, esto se puede ver en la Figura \ref{fig:labeling12}.
\clearpage
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{imagenes/deteccionvstracker.png}
	\caption{Comparación entre usar solo la detección y usar tracker con detección.}
	\source{Elaboración propia.}
	\label{fig:labeling12}
\end{figure}

Cómo se ve en la figura anterior, no se marca todos los objetos en el lado que no utiliza \textit{tracker}, ya que justo en ese \textit{frame} no lo identifica bien y se pierde. Pero en otra parte del mismo video se ve que en la Figura \ref{fig:labeling13}, desaparece el objeto detectado, por otra parte el que utiliza el \textit{tracker} no pierde ninguna detección.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{imagenes/deteccionvstracker2.png}
	\caption{Error al solo usar la detección en un proyecto.}
	\source{Elaboración propia.}
	\label{fig:labeling13}
\end{figure}


Pero el problema mas importante es que cuando una persona se sale del enfoque de la cámara o es cubierto por algún objeto, la detección se pierde y cuando vuelve a aparecer la app lo detecta como si fuera una nueva persona. 
Esto se podrá solucionar incorporando a la detección un \textit{tracker}, mediante esto se podrá generar ID a cada detección y con eso se podrá diferenciar entre detecciones, ya que todos tendrán un identificador que permitiría contar a las personas detectadas.
El \textit{tracker} a utilizar es DeepSort, el cual es de uso libre, para que funcione correctamente se tiene que usar una red pre-entrenada que ayuda al proceso del rastreo.
\clearpage

\subsection{Agregar contador y límite de detección}

Para que se pueda contar la cantidad de personas detectas se usara una función de Deepsort el cual genera una lista de las detecciones y mediante OpenCV se podrá mostrar en la pantalla del mismo video como se ve en la Figura \ref{fig:labeling14}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.35]{imagenes/persona19.png}
	\caption{Contador de personas en un video.}
	\source{Elaboración propia}
	\label{fig:labeling14}
\end{figure}

El límite se encargará de reiniciar el contador y los cálculos de tiempo máximo de espera de un cliente en una fila. En la Figura \ref{fig:labeling35} se aprecia cómo se muestra el límite creado, esta línea es solo una representación visual, ya que las coordenadas de la línea son los importantes al momento de trabajar en la aplicación.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona20.png}
	\caption{Línea que limita las detecciones en un video.}
	\source{Elaboración propia}
	\label{fig:labeling35}
\end{figure}

Esto se logra gracias a OpenCV, ya que con él se dibujara una línea, el cual representa el límite para la detección y cuando un objeto cruce la línea ya no será tomando en cuenta. Esto funciona porque por cada detección genera unas coordenadas de la posición del objeto, teniendo esto se sabe cuándo cruza la línea.

\subsection{Alarma al superar el tiempo máximo}

Este apartado se encarga de informar cuando se sobrepase el tiempo máximo de espera definido, para saber esto se creó una lista donde se registra la hora en la que se detectó la persona, en la Figura \ref{fig:labeling16} se observa como está compuesta la lista, la cual guarda datos necesarios para realizar la alarma y el límite de detección.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona21.png}
	\caption{Lista que guarda datos cada vez que se realiza una nueva detección.}
	\source{Elaboración propia}
	\label{fig:labeling16}
\end{figure}

Teniendo esta lista podemos registrar la hora en la que fue detectado una persona y con ello al tener una lista donde se detectaron 3 personas nos permite calcular un tiempo promedio de espera y con ese dato se podrá comparar con el tiempo máximo de espera.
Si este tiempo promedio de espera es mayor que el tiempo máximo, se procederá a notificar mediante un \say{popup} que el cliente está esperando mucho y que se recomienda abrir una nueva caja.
\\

Otra manera en la que se puede activar la alarma es cuando por un determinado tiempo ni una persona llegó a cruzar el límite definido, de igual manera que en el anterior caso se activará un \say{popup} notificando un problema al encargado para determinar si lo ve necesario abrir una caja o no. En la Figura \ref{fig:labeling17} se observa el diseño del \say{popup} y el mensaje que da.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona22.png}
	\caption{Alerta popup que se activa cuando se alcanza el tiempo máximo de espera.}
	\source{Elaboración propia}
	\label{fig:labeling17}
\end{figure}

\clearpage

\subsection{Crear una base de datos}

Con este apartado se está utilizando una base datos para registrar la hora exacta cuando salte una alarma. Esto sirve para poder ver cuándo son las horas críticas y así buscar una solución que mejoraría la atención.
Para la base de datos se usa Mongodb, el cual te permite guardar los datos tanto de manera local como en la nube y es una herramienta gratuita.

En este caso como aplicación fue probada en un MacBook Pro 2014, la instalación de Mongodb variará en una máquina Windows. Simplemente para instalar la base de datos se tendrá que correr el siguiente comando que aparece en la Figura \ref{fig:labeling18}, estos comandos se tienen que hacer correr en la terminal.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.55]{imagenes/mongodc.png}
	\caption{Comando de instalación en Mac de MongoDB.}
	\source{Elaboración propia}
	\label{fig:labeling18}
\end{figure}

El dato que se guardará es la hora en la que la alarma se active, esto se logra con los siguientes comandos que aparecen en el siguiente Código \ref{24}, estos tienen que estar dentro de la aplicación creada.
 \begin{lstlisting}[language=Python,caption={Comando para guardar información en la base de datos.},captionpos=b,label=24]
post = {"data": datetime.now()}
alarms = db.alarms
alarms.insert_one(post)
DETECTION_EVENTS.clear()
\end{lstlisting}

En este caso la información de la base de datos se almacena de manera local, lo que significa que cada vez que se inicie la aplicación se tendrá que activar MongoDB, esto se logra con el siguiente comando que aparece en la Figura \ref{fig:labeling20}, de la misma manera se tendrá que desactivar cuando ya no se utilice la aplicación. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona25.png}
	\caption{Comandos para iniciar y detener la base de datos.}
	\source{Elaboración propia}
	\label{fig:labeling20}
\end{figure}

\clearpage

\section{Conclusiones del capitulo III}

En el presente capítulo se explica la elección de la red neuronal YOLO y a su vez se desarrolla todo el procedimiento para poder entrenarlo haciendo uso de Darkflow. Con la red neuronal entrenada se procede a explicar las diferentes funciones que tendrá la aplicación y los sistemas que lo componen.
















