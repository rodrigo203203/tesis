\section{Elección de una red neuronal}
Para la elección de la red neuronal se tomó en cuenta un estudio realizado por el equipo de YOLO (\cite{persona}), este equipo realizo pruebas con diferentes redes neuronales para poder demostrar el gran rendimiento que tiene la red YOLO, estas pruebas fueron hechas en la misma computadora, el resultado de estas pruebas se puede observar en la Figura \ref{fig:labeling3}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{imagenes/persona9.png}
	\caption{Comparación de YOLO y otros detectores de objetos de última generación.}
	\source{YOLOv4: Optimal Speed and Accuracy of Object Detection. (2020)}
	\label{fig:labeling3}
\end{figure}

Estas pruebas fueron realizadas haciendo el uso de la base de datos \say{COCO}, que es una recopilación de cientos de miles de imágenes con millones de objetos ya etiquetados que ya están preparados para realizar un entrenamiento, lo cual facilita a realizar pruebas de las diferentes redes neuronales. Con estos resultados nos muestran que la red neuronal YOLO es la mejor opción, ya que cuenta con una gran velocidad sin perder mucha precisión al momento de detectar los diferentes objetos. Por otra parte, la red YOLOv3 presenta resultados interesantes, ya que tiene una gran velocidad pero a un gran costo en su precision y dependiendo de la aplicación podría ser una buena elección.

\section{Entrenamiento de la red neuronal} 

En este capítulo se irá desarrollando los diferentes pasos para lograr un buen entrenamiento de una red neuronal, en este caso el objetivo del entrenamiento es que sea capaz de detectar personas.  

\subsection{Base de datos} 

Para lograr el entrenamiento de la red neuronal, primeramente, se tiene que construir una base de datos, esta base tiene que estar compuesta por imágenes donde aparezcan personas. Posteriormente, comienza un proceso de \say{etiquetado}, en el cual se tiene que señalar donde se encuentra la persona en las diferentes imágenes, este procedimiento se realiza con la aplicación LabelImg, este proceso se observa en la Figura \ref{fig:labeling}. 
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.25]{imagenes/persona1.png}
	\caption{Proceso de etiquetado para generar los archivos necesarios para el entrenamiento.}
	\source{Elaboración propia}
	\label{fig:labeling}
\end{figure}

Este proceso se tiene que realizar con cada imagen, para así obtener un archivo que especifica la posición de dónde se encuentra la \say{persona} en la imagen. En la Figura \ref{fig:labeling2} se observa la manera en la que se guardan esos datos. De esta manera se obtiene una base de datos que sirve para entrenar la red neuronal YOLO, la cual debe estar compuesta por lo menos con 400 imágenes. 

\clearpage

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{imagenes/persona2.png}
	\caption{Coordenadas obtenidas por el programa LabelImg al etiquetar a un objeto.}
	\source{Elaboración propia}
	\label{fig:labeling2}
\end{figure}

Este procedimiento se puede realizar más rápido gracias a la base de datos de Google, el cual tiene una gran cantidad de imágenes ya etiquetadas lo que facilita el proceso de realizar un entrenamiento, esto se observa mejor en la Figura \ref{fig:labeling5}. El único inconveniente de esta herramienta es que la base de datos está en un formato que Darknet no lo reconoce, pero ya existen otras herramientas que permiten convertir a un formato con la cual se puede trabajar. 
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.2]{imagenes/persona5.png}
	\caption{Base de datos de Google para el entrenamiento de redes neuronales.}
	\source{Elaboración propia}
	\label{fig:labeling5}
	\end{figure}

\subsection{Preparación del ambiente}

Al momento de entrenar una red neuronal se utiliza muchos recursos de la computadora, sobre todo en el apartado del GPU, ya que la mayoría de los cálculos se realizan de mejor manera en esa parte. Esto resulto ser un problema ya que mi computadora no cuenta con una GPU dedicada y los entrenamientos se realizaban de manera muy lenta, por ese motivo se optó por usar Colab, el cual es un servicio de Google que te permite realizar entrenamientos de redes neuronales ya que te deja usar los GPU's de sus servidores. 
\\ 

Colab es un editor de texto online, que te permite escribir tu código y probarlo sin la necesidad de instalar programas en tu computadora, pero será necesarios instalarlos en tu editor online. El primer paso es instalar Darknet, el cual te permite trabajar con YOLO.  

\clearpage 

Para qué Darknet funcione correctamente necesita diferentes frameworks, en la Figura \ref{fig:labeling42} se puede observar una lista con los frameworks necesarios. Para poder instalarlos se utiliza el comando \say{pip}, el cual es un sistema de gestión de paquetes de Python. La mayoría de estos frameworks ya vienen instalados por defecto en Colab por ser muy utilizados. 
 
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona3.png}
	\caption{Dependencias necesarias para que funcione Darknet.}
	\source{Elaboración propia}
	\label{fig:labeling42}
\end{figure}

\subsection{Personalizar una red neuronal}

La red neuronal YOLO y Tiny-Yolo viene por defecto entrenada con varias clases que le permite detectar diferentes objetos, pero ninguna se podía ajustar a las necesidades del proyecto y por eso mismo se tuvo que realizar un entrenamiento con una base de datos propia. 

Antes de modificar los parámetros, se decidió usar la Tiny-Yolo debido a que es una red neuronal más liviana (con menos capas), lo que ocasiona que sea menos exigente cuando se tiene que procesar las detecciones, lo que permite que funcione de mejor manera en mi computadora. 

La diferencia de rendimiento se podrá ver de mejor manera en la Tabla \ref{tab:fruta}, el cual da cómo mejor opción Tiny-Yolo teniendo un mejor rendimiento que al usar YOLO. El único problema de usar Tiny-Yolo es que se pierde un poco de precisión al momento de realizar las detecciones. 

\begin{table}[h]
\caption{Resultados de una prueba de rendimiento entre YOLO y Tiny-Yolo.}
\begin{center}
\begin{tabular}{cc} 
\hline
\textbf{Versión de Yolo} & \textbf{FPS}  \\ 
\hline
Tiny-yolo                & 7-10          \\
YOLO                     & 1-3           \\
\hline
\end{tabular}
\label{tab:fruta}
\vspace{3mm}
\sources{Elaboración propia.}
\end{center}
\end{table}

Estos resultados demuestran que la mejor opción es trabajar con Tiny-Yolo, por lo cual se modificara el archivo \say{yolov4-tiny.cfg}, en el cual se cambiaran ciertos parámetros para que la red neuronal al momento de entrenar se adapte a los requerimientos del proyecto. los parámetros que se modificaron están señalados en la Figura \ref{fig:labeling6}. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona6.png}
	\caption{Se define el learning rate.}
	\source{Elaboración propia}
	\label{fig:labeling6}
\end{figure}

El dato marcado \textit{learning rate} es una ponderación que se asigna a la nueva información que ingresa a la red, este valor entre más bajo sea aumentara la duración del entrenamiento pero se podrá conseguir una predicción menos volátil. Un valor muy bajo no es muy útil ya que no aplicaría ninguna mejora al entrenamiento, pero sí alargaría el tiempo de finalización.

El siguiente es \textit{max batches}, el que se encarga de limitar el número de pasos máximos que realizará en el entrenamiento. Este número es obtenido mediante una simple fórmula que se observa en la Ecuación \ref{eq:maxb}, pero solo es aplicada cuando se trabajará con 3 o más clases de detección, caso contrario simplemente se tendrá que colocar \say{6000}, como es en este caso. En \textit{step} se tomará el 80\% y 90\% de \say{max batches} respectivamente. 

\begin{equation}
\label{eq:maxb}
	max\_batches = \#\operatorname{clases} * 2000
\end{equation}

Otros parámetros que se tienen que modificar son los datos marcados que aparecen en la Figura \ref{fig:labeling7}, que consiste en definir la cantidad de filtros y especificar cuántas clases tendrá que aprender la red neuronal. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona7.png}
	\caption{Se establece la cantidad de filtros a usarse.}
	\source{Elaboración propia}
	\label{fig:labeling7}
\end{figure}

Para calcular la cantidad de filtros se hará uso de una fórmula simple que se puede apreciar en la Ecuación \ref{eq:clases}, este dato obtenido se tendrá cambiar en todos los filtros que se encuentra en el documento \say{yolov4-tiny.cfg}.

\begin{equation}
	filtros = (\#\operatorname{clases}+5)*3
	\label{eq:clases}
\end{equation}

Con esto se finaliza los cambios en el archivo \say{yolov4-tiny.cfg}, pero aún falta editar otros 2 archivos más el cual uno definirá el nombre de la clase y en el otro se definirán la ubicación de los archivos necesarios para entrenar, la locación de donde se guardará la red entrenada y cuantas clases se usará para entrenar, esto se aprecia en la Figura \ref{fig:labeling45}. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona8.png}
	\caption{Se detalla la cantidad de clases y nombres que se usarán para entrenar la red neuronal.}
	\source{Elaboración propia}
	\label{fig:labeling45}
\end{figure}

\subsection{Inicio de entrenamiento}

Para iniciar el entrenamiento se tiene que preparar todos los archivos en el ambiente Colab, primeramente, se tiene que cargar todas las imágenes ya etiquetadas y de ahí se procedería a ejecutar los siguientes comandos que se observan en la Figura \ref{fig:labeling46}, el cual creará unos archivos basados con la cantidad de clases por el cual se entrenara.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona11.png}
	\caption{Comando para generar archivos que guiaran el entrenamiento.}
	\source{Elaboración propia}
	\label{fig:labeling46}
\end{figure}

Una vez teniendo los archivos generados se procede a iniciar el entrenamiento mediante el siguiente comando que aparece en la Figura \ref{fig:labeling47}. La duración de este entrenamiento dependerá de la cantidad de imágenes que se está usando para realizar el entrenamiento, en este caso el entrenamiento duro aproximadamente 4 horas, pero se repitió 2 veces para mejorar los resultados obtenidos. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona12.png}
	\caption{Comando para iniciar el entrenamiento.}
	\source{Elaboración propia}
	\label{fig:labeling47}
\end{figure}

Al finalizar el entrenamiento ya se obtendrá una red neuronal funcional, capaz de detectar personas. Un resultado de este entrenamiento se observa en la Figura \ref{fig:labeling48}, donde se ven marcadas una cantidad aceptable de personas que aparecen en la imagen, cada recuadro que marca a una persona viene con un numero el cual indica el porcentaje de seguridad de detención realizada por la red neuronal. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona14.png}
	\caption{Resultado del entrenamiento realizado.}
	\source{Elaboración propia}
	\label{fig:labeling48}
\end{figure}

\section{Prueba de rendimiento}

Una vez entrenada la red neuronal se procede a realizar unas diversas pruebas para así poder calcular el rendimiento y sobre todo la precisión de esta red construida. Para estas pruebas se está usando la documentación que proporciona la página de desarrolladores de Google, donde se detalla la manera en la que se tiene que realizar estas pruebas para calcular la precisión. 

Para estas pruebas se está usando un video de vigilancia que fue proporcionado por el supermercado Makro, la posición de la cámara permite capturar bien la fila que se genera en el supermercado. Este video será analizado por la red neuronal y así calcular cuantas personas fueron detectadas para así realizar una comprobación que permita confirmar si la cantidad de personas detectadas es la correcta.   

Una vez procesado el video por la red neuronal se extrajo 44 imágenes, con estas imágenes se procedió a realizar el análisis el cual permitiría medir la precisión de esta red neuronal. Para ellos las diferentes detecciones se dividió en 3 diferentes categorías, estas categorías son: verdadero positivo (VP), falso positivo (FP) y falso negativo (FN). 

Para una detección sea considerado como VP, debe tener un 70\% de confiabilidad en la detección y también tiene que encerrar casi por completo al objeto detectado. Por otra parte, para que la detección sea considerada como FP debe tener una confiabilidad menor a 70\% o que enmarque una detección errónea y para que pertenezca al grupo de FN el objeto no tiene que ser detectado por la red neuronal. Esto se podrá entender mejor en la Figura \ref{fig:FN} 

\clearpage

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/verdaderonega.png}
	\caption{Clasificación de las diferentes detecciones obtenidas.}
	\source{Elaboración propia}
	\label{fig:FN}
\end{figure}

Todas las imágenes obtenidas fueron clasificadas mediante la explicación anterior, con lo cual se obtuvo en total de 182 VP, 73 FP, 68 FN y 64 VN. En la Tabla \ref{tab:FP}, se observa cómo se clasifico las detecciones y los tiempos en la cual se obtuvo la imagen para ser analizados. 

\begin{table}[h]
\centering
\caption{Datos obtenidos mediante el análisis realizado de las detecciones de la red neuronal.}
\begin{tabular}{ccccc} 
\hline
\multicolumn{1}{c}{TIEMPO} & \multicolumn{1}{c}{\textbf{Verdadero Positivo}} & \multicolumn{1}{c}{\textbf{Falso Positivo}} & \multicolumn{1}{c}{\textbf{Falso Negativo}} & \multicolumn{1}{c}{\textbf{Verdadero Negativo}}  \\ 
\hline
0:18                       & 3                                               & 4                                           & 2                                           & 2                                                \\
0:28                       & 4                                               & 3                                           & 2                                           & 2                                                \\
0:38                       & 2                                               & 4                                           & 3                                           & 3                                                \\
0:48                       & 7                                               & 0                                           & 2                                           & 2                                                \\
0:59                       & 4                                               & 1                                           & 1                                           & 1                                                \\
1:11                       & 3                                               & 1                                           & 2                                           & 1                                                \\
1:21                       & 3                                               & 1                                           & 1                                           & 1                                                \\
\hline
\end{tabular}
\label{tab:FP}
\vspace{3mm}
\sources{Elaboración propia.}
\end{table}

Cómo se puede observar en la tabla anterior, todos los datos fueron repartidos respectivamente en las diferentes categorías. Con estos datos y la siguiente Ecuación \ref{eq:vpvf}, se podrá calcular la precisión de la red neuronal. 

\begin{equation}
\label{eq:vpvf}
	\text{Precisión}=\frac{VP}{VP + FP} 
\end{equation}

\begin{center}
\begin{list}{}{}
	\item \textbf{VP} = Sumatoria total de verdaderos positivos.
	\item \textbf{FP} = Sumatoria total de falsos positivos.
\end{list}
\end{center}

Utilizando la anterior ecuación obtenemos una precisión del 71\%, la cual es bastante alto y demuestra una confiabilidad de los resultados que podrá obtener la red neuronal. Pero para poder demostrar el rendimiento se tiene que obtener la curva ROC, para poder obtener esta gráfica será necesario obtener la tasa de verdaderos positivos y la tasa de falsos positivos. 

Para poder obtener la tasa de verdaderos positivos se hara uso de la Ecuacion \ref{eq:vpvfss} y para tasa de falsos positivos se usara la Ecuacion \ref{eq:vpvfws}.

\begin{equation}
\label{eq:vpvfss}
	\text{Tasa de verdaderos positivos (TVP)} =\frac{VP}{VP + FN} 
\end{equation}

\begin{center}
\begin{list}{}{}
	\item \textbf{VP} = Verdadero positivo.
	\item \textbf{FN} = Falso negativo.
\end{list}
\end{center}

\begin{equation}
\label{eq:vpvfws}
	\text{Tasa de falsos positivos (TFP)} =\frac{FP}{FP + VN} 
\end{equation}

\begin{center}
\begin{list}{}{}
	\item \textbf{FP} = Falso positivo.
	\item \textbf{VN} = Verdadero negativo.
\end{list}
\end{center}

Una vez utilizando estas ecuaciones en los datos de la Tabla \ref{tab:FP} se obtendrá las datos necesarios para poder obtener la curva ROC, estos datos se podrán observar en la Tabla \ref{tab:TVFTFV}. 

\begin{table}[h]
\centering
\caption{Datos necesarios para obtener la curva ROC que indica el rendimiento de la red neuronal.}
\begin{tabular}{cc} 
\hline
\multicolumn{1}{c}{\textbf{TVP}} & \multicolumn{1}{c}{\textbf{TFP}}  \\ 
\hline
0,6                              & 0,666667                          \\
0,666667                         & 0,6                               \\
0,4                              & 0,571429                          \\
0,777778                         & 0                                 \\
0,8                              & 0,5                               \\
0,6                              & 0,5                               \\
0,75                             & 0,5                               \\
\hline
\end{tabular}
\vspace{3mm}
\label{tab:TVFTFV}
\sources{Elaboración propia.}
\end{table}

Con la tabla anterior ya se tiene todos los datos para obtener la curva ROC, pero para poder graficarlo es necesario que cada dato de la TFP reste a 1, como se indica en la Ecuación \ref{eq:v1}. Una vez realizado esto los datos tendrán que ser ordenados de forma ascendente.

\begin{equation}
\label{eq:v1}
		1 - TFP  
\end{equation}
 
Con estos datos se obtiene la curva ROC, que indica el rendimiento que posee la red neuronal entrenada. Esto se podrá observar en la Figura \ref{fig:FROC}, Los datos de las tablas anteriores no está completas ya que se analizaron varios objetos, por eso mismo las tablas completas se podrá observar en el apartado de los anexos del documento. 

\clearpage

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{imagenes/rocsi.png}
	\caption{Gráfica de rendimiento de la red neuronal entrenada.}
	\source{Elaboración propia}
	\label{fig:FROC}
\end{figure}

Teniendo la gráfica se procede a calcular el area bajo la curva o AUC por sus siglas en ingles, con este dato se podrá definir si esta red entrenada tiene un buen rendimiento, para calcular el AUC se usara los datos de la Tabla \ref{tab:TVFTFV} y se aplicara la siguiente Ecuación \ref{eq:auc}, posteriormente, se usara la sumatoria de todos los datos obtenidos para así tener el AUC de la curva ROC.

\begin{equation}
\label{eq:auc}
	AUC=\frac{TVP_{n}+TVP_{n+1}}{2*(TFP_{n+1}-TFP_{n})}
\end{equation}
\begin{center}
\begin{list}{}{}
	\item \textbf{TVPn} = Dato en la posición n en la tabla de tasas de verdaderos positivos.
	\item \textbf{TFPn} = Dato en la posición n+1 en la tabla de tasas de falsos positivos.
\end{list}
\end{center}

Aplicando la ecuación anterior se obtuvo un valor de 0.63, lo que indica que el rendimiento de la red no es bueno, para que una red entrenada tenga un rendimiento óptimo deberá tener un valor superior a 0.7. 

Este valor de 0.63 podría mejorar realizando entrenamientos más largos a la red neuronal, tanto en la cantidad de iteraciones que tendría que dar como la cantidad de imágenes con la cual entrena, estas imágenes en su preferencia deberán ser más variadas.  


Un factor que podría ocasionar un bajo rendimiento a la red es la posición de la cámara de donde se obtuvo el video y se realizaron las pruebas. Como se ve en la figura cuando hay una fila larga las personas están muy apegadas entre sí y eso no le permite identificar bien a las personas. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{imagenes/pruebared.png}
	\caption{Imagen del video donde se realizo las pruebas de rendimiento.}
	\source{Elaboración propia}
	\label{fig:FROC}
\end{figure}

\section{Diseño de la interfaz} 

Para el diseño de la interfaz se utilizó la herramienta Balsamiq Wireframes, el cual permite planificar cómo se vera la interfaz de alguna aplicación. Con esta herramienta se diseñó 2 pantallas para así determinar el diseño que tendrá la aplicación. 

\subsection{Detección de personas} 

Esta es la pantalla principal de la aplicación, donde se indica la información de cuántas personas están siendo detectadas en ese momento, de igual manera se muestra en tiempo real el video obtenido por la cámara de seguridad. Otra información importante que se indica en la interfaz es el límite de detección, el cual ayuda a visualizar mejor los datos de esta pantalla, esto se apreciará mejor en la Figura \ref{fig:labeling30}. 


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/imagen1.png}
	\caption{Pantalla principal de la aplicación NeoVision.}
	\source{Elaboración propia}
	\label{fig:labeling30}
\end{figure}

\subsection{Pantalla de alerta}

Esto es una pantalla de alerta que solo aparecerá cuando se pase el límite de tiempo de espera de una persona en la fila del supermercado. Esta pantalla tendrá una imagen de alerta para así poder captar la atención de las personas y se aconsejará abrir una nueva caja para poder acelerar el proceso de atención, el diseño de esta pantalla se puede ver en la Figura \ref{fig:labeling31}. 


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/imagen2.png}
	\caption{Mockup de la pantalla de alerta.}
	\source{Elaboración propia}
	\label{fig:labeling31}
\end{figure}

\section{Diagrama de flujo}
En este apartado se mostrará un diagrama de flujo en el que se representa los principales procesos de este proyecto, cuáles son detectar a personas y dependiendo del tiempo de espera notificar con una alerta, este diagrama se observa en la Figura \ref{fig:labeling33}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=1]{imagenes/NeoVision3.png}
	\caption{Diagrama de flujo explicativo sobre la función de la aplicación NeoVision.}
	\source{Elaboración propia}
	\label{fig:labeling33}
\end{figure}

\clearpage
\section{Diagrama C4Model}
En este apartado se dará conocer un esquema siguiendo el modelo C4Model, el cual se va explicando de manera general hasta llegar a lo más específico, empezando por el contexto de la situación, sus contenedores, componentes y por último un diagrama de todas las clases.

\subsection{Contexto}
En este apartado se observará las diferentes interacciones que tiene la aplicación, esto se apreciará mejor en la Figura \ref{fig:labeling32}.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/contenido2.png}
	\caption{Diagrama de contexto que representa las interacciones del sistema.}
	\source{Elaboración propia}
	\label{fig:labeling32}
\end{figure}
Con este diagrama se puede mostrar cuáles son las interacciones que realiza la aplicación, como ser el personal de sistemas es el que inicia la aplicación y si es necesario configura ciertos parámetros, por otra parte, la aplicación interactúa con el personal de seguridad mediante avisos que ejecutara cuando el tiempo de espera de una persona sobrepase el tiempo configurado.
\subsection{Contenedores}

En esta sección se observa más a detalle los sistemas usados para que la aplicación funcione, esto se ve en la Figura \ref{fig:labeling34}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/contenedor3.png}
	\caption{Diagrama de contenedores que representa las diferentes funciones de los sistemas.}
	\source{Elaboración propia}
	\label{fig:labeling34}
\end{figure}

Con este diagrama conocemos cuáles son las funciones de los diferentes sistemas que tiene la aplicación, por ejemplo, Darknet es el encargado de realizar las detecciones en las imágenes que le envía la aplicación principal. Por otra parte, Deepsort es el que recibe los resultados de Darknet y este aplica un ID único a cada detección, esta información es recibida por NeoVision, la cual le permite realizar los cálculos para determinar si es necesario abrir una nueva caja.  

\section{Descripción de la aplicación} 

Para comenzar el desarrollo de la aplicación primeramente se tiene que crear un ambiente virtual de Python en la computadora, ya que se necesita instalar ciertos paquetes que podrían entrar en conflicto con algunas aplicaciones ya instaladas y también genera un mayor orden. 

La herramienta ideal para realizar esto es VirtualenvWrapper, ya que es fácil de instalar y sobre todo es simple de ingresar al ambiente virtual, sobre todo cuando se compara con otras herramientas. Esta diferencia aprecia mejor en la Figura \ref{fig:labeling9}. 

\clearpage
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona15.png}
	\caption{Diferencia entre iniciar un ambiente virtual de Python entre VirtualWrapper y Virtualenv.}
	\source{Elaboración propia}
	\label{fig:labeling9}
\end{figure}


Con el ambiente virtual se procede a instalar los diversos paquetes necesarios, donde los principales son Tensorflow y OpenCV. Teniendo estos recursos instalados, se procede a convertir la red neuronal entrenada que se encuentra en un formato \say{.weights}, a un formato que Tensorflow soporte. Para ello usaremos un código disponible hecho por la misma comunidad, que está hecho en Python, en la Figura \ref{fig:labeling10} se muestra el comando para convertir la red.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{imagenes/convertir_yolo.png}
	\caption{Comando para convertir la red neuronal.}
	\source{Elaboración propia}
	\label{fig:labeling10}
\end{figure}

 Para realizar la aplicación se hará uso del editor PyCharm, porque es gratis y tiene una interfaz intuitiva al momento de usarlo.
 El primer paso al comenzar la aplicación es comenzar a importar todos los paquetes que se necesitará para que funcione, la manera en la que se importa los paquetes se podrá observar en el siguiente Código \ref{23}.
 \vspace{5mm}

\begin{lstlisting}[language=Python,caption={Manera en la que se importan los diferentes paquetes al programa.},captionpos=b,label=23]
	import os 
	import subprocess
	from datatime import datetime
	import tensorflow as tf
	import time
\end{lstlisting}
\vspace{5mm}

Con todo esto ya se puede dar comienzo para que la aplicación pueda leer los videos mediante OpenCV y así iniciar el detector para que encuentre las personas de un video.

\subsection{Agregar el tracker a la detección}

Por sí solas la detección que se puede hacer no brinda la información suficiente como para contar las detecciones o corregir errores que se pueden generar. Uno de estos errores es que como en un video hay objetos en movimiento simplemente puede desaparecer las detecciones, debido a que por el movimiento no se llega a reconocer al objeto, esto se puede ver en la Figura \ref{fig:labeling12}.
\clearpage
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{imagenes/deteccionvstracker.png}
	\caption{Comparación entre usar solo la detección y usar tracker con detección.}
	\source{Elaboración propia.}
	\label{fig:labeling12}
\end{figure}

Cómo se ve en la figura anterior, no se marca todos los objetos en el lado que no utiliza \textit{tracker}, ya que justo en ese \textit{frame} no lo identifica bien y se pierde. Pero en otra parte del mismo video se ve que en la Figura \ref{fig:labeling13}, desaparece el objeto detectado, por otra parte, el que utiliza el \textit{tracker} no pierde ninguna detección. 

\vspace{5mm}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{imagenes/deteccionvstracker2.png}
	\caption{Error al solo usar la detección en un proyecto.}
	\source{Elaboración propia.}
	\label{fig:labeling13}
\end{figure}
\vspace{5mm}

Pero el problema más importante es que cuando una persona se sale del enfoque de la cámara o es cubierto por algún objeto, la detección se pierde y cuando vuelve a aparecer la app lo detecta como si fuera una nueva persona.  

Esto se podrá solucionar incorporando a la detección un \textit{tracker}, mediante esto se podrá generar ID a cada detección y con eso se podrá diferenciar entre detecciones, ya que todos tendrán un identificador que permitiría contar a las personas detectadas. 

El \textit{tracker} a utilizar es DeepSort, el cual es de uso libre, para que funcione correctamente se tiene que usar una red pre-entrenada que ayuda al proceso del rastreo. 

\clearpage 
\subsection{Agregar contador y límite de detección}

Para que se pueda contar la cantidad de personas detectas se usara una función de Deepsort el cual genera una lista de las detecciones y mediante OpenCV se podrá mostrar en la pantalla del mismo video como se ve en la Figura \ref{fig:labeling14}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{imagenes/persona19.png}
	\caption{Contador de personas en un video.}
	\source{Elaboración propia}
	\label{fig:labeling14}
\end{figure}

El límite se encargará de reiniciar el contador y los cálculos de tiempo máximo de espera de un cliente en una fila. En la Figura \ref{fig:labeling35} se aprecia cómo se muestra el límite creado, esta línea es solo una representación visual, ya que las coordenadas de la línea son los importantes al momento de trabajar en la aplicación.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona20.png}
	\caption{Línea que limita las detecciones en un video.}
	\source{Elaboración propia}
	\label{fig:labeling35}
\end{figure}

\clearpage
Esto se logra gracias a OpenCV, ya que con él se dibujará una línea, el cual representa el límite para la detección y cuando un objeto cruce la línea ya no será tomando en cuenta. Esto funciona porque por cada detección genera unas coordenadas de la posición del objeto, teniendo esto se sabe cuándo cruza la línea. 

\subsection{Alarma al superar el tiempo máximo} 

Este apartado se encarga de informar cuando se sobrepase el tiempo máximo de espera definido, para saber esto se creó una lista donde se registra la hora en la que se detectó la persona, en la Figura \ref{fig:labeling16} se observa cómo está compuesta la lista, la cual guarda datos necesarios para realizar la alarma y el límite de detección. 

\vspace{5mm}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona21.png}
	\caption{Lista que guarda datos cada vez que se realiza una nueva detección.}
	\source{Elaboración propia}
	\label{fig:labeling16}
\end{figure}
\vspace{5mm}

Teniendo esta lista podemos registrar la hora en la que fue detectado una persona y con ello al tener una lista donde se detectaron 3 personas nos permite calcular un tiempo promedio de espera y con ese dato se podrá comparar con el tiempo máximo de espera.
Si este tiempo promedio de espera es mayor que el tiempo máximo, se procederá a notificar mediante un \say{popup} que el cliente está esperando mucho y que se recomienda abrir una nueva caja.
\\

Otra manera en la que se puede activar la alarma es cuando por un determinado tiempo ni una persona llegó a cruzar el límite definido, de igual manera que en el anterior caso se activará un \say{popup} notificando un problema al encargado para determinar si lo ve necesario abrir una caja o no. En la Figura \ref{fig:labeling17} se observa el diseño del \say{popup} y el mensaje que da.

\vspace{5mm}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.45]{imagenes/persona22.png}
	\caption{Alerta popup que se activa cuando se alcanza el tiempo máximo de espera.}
	\source{Elaboración propia}
	\label{fig:labeling17}
\end{figure}


\subsection{Crear una base de datos}

Con este apartado se está utilizando una base datos para registrar la hora exacta cuando salte una alarma. Esto sirve para poder ver cuándo son las horas críticas y así buscar una solución que mejoraría la atención. 

Para la base de datos se usa Mongodb, el cual te permite guardar los datos tanto de manera local como en la nube y es una herramienta gratuita. 

En este caso como aplicación fue probada en un MacBook Pro-2014, la instalación de Mongodb variará en una máquina Windows. Simplemente para instalar la base de datos se tendrá que correr el siguiente comando que aparece en la Figura \ref{fig:labeling18}, estos comandos se tienen que hacer correr en la terminal. 

\vspace{5mm}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.55]{imagenes/mongodc.png}
	\caption{Comando de instalación en Mac de MongoDB.}
	\source{Elaboración propia}
	\label{fig:labeling18}
\end{figure}

El dato que se guardará es la hora en la que la alarma se active, esto se logra con los siguientes comandos que aparecen en el siguiente Código \ref{24}, estos tienen que estar dentro de la aplicación creada.
\vspace{5mm}

 \begin{lstlisting}[language=Python,caption={Comando para guardar información en la base de datos.},captionpos=b,label=24]
post = {"data": datetime.now()}
alarms = db.alarms
alarms.insert_one(post)
DETECTION_EVENTS.clear()
\end{lstlisting}
\vspace{5mm}

En este caso la información de la base de datos se almacena de manera local, lo que significa que cada vez que se inicie la aplicación se tendrá que activar MongoDB, esto se logra con el siguiente comando que aparece en la Figura \ref{fig:labeling20}, de la misma manera se tendrá que desactivar cuando ya no se utilice la aplicación. 

\vspace{5mm}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona25.png}
	\caption{Comandos para iniciar y detener la base de datos.}
	\source{Elaboración propia}
	\label{fig:labeling20}
\end{figure}


\section{Conclusiones del capitulo III}

En el presente capítulo se explicó el motivo de la elección de la red neuronal, la cual es YOLO. Teniendo echa la elección se decidió realizar pruebas para saber que versión de YOLO se adapta mejor al proyecto y con esos resultados se optó por Tiny-Yolo. 
\\ 
Con la red neuronal seleccionada se procedió a realizar el respectivo entrenamiento para que pueda detectar a personas y así poder utilizar la información obtenida para calcular el tiempo promedio de espera de las personas que están esperando en una fila. Posteriormente, se explicó el funcionamiento de la aplicación y cómo el usuario puede interactuar con la interfaz. 

En el siguiente capítulo se explicará el funcionamiento de la aplicación y las diversas funciones claves que permiten realizar los cálculos dependiendo de las detecciones realizadas, por otra parte, se verá un ejemplo de un caso de uso de la aplicación y se analizara los datos que se consiguen con esa prueba. 

   
















