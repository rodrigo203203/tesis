\section{Elección de una red neuronal}
Para la elección de la red neuronal se tomó en cuenta un estudio realizado por el equipo de YOLO (\cite{persona}), este equipo realizo pruebas con diferentes redes neuronales para poder demostrar el gran rendimiento que tiene la red YOLO, estas pruebas fueron hechas en la misma computadora, el resultado de estas pruebas se puede observar en la Figura \ref{fig:labeling3} que da como ganador la red neuronal YOLO.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{imagenes/persona9.png}
	\caption{Comparación de YOLO y otros detectores de objetos de última generación.}
	\source{YOLOv4: Optimal Speed and Accuracy of Object Detection. (2020)}
	\label{fig:labeling3}
\end{figure}

Estas pruebas fueron realizadas haciendo el uso de la base de datos \say{coco}, que recopila una gran información que facilita la detección de diferentes objetos. Con estos resultados nos muestran que la red neuronal YOLO es la mejor opción, ya que cuenta con una gran velocidad sin perder mucha precisión al momento de detectar los diferentes objetos. Otra red que tiene resultados muy buenos es YOLOv3, es algo lento pero tiene una gran precisión y dependiendo de la aplicación podría ser una buena elección.

\section{Entrenamiento de la red neuronal}
En este capítulo se ira desarrollando los diferentes pasos para lograr un buen entrenamiento de una red neuronal, en este caso el objetivo del entrenamiento es que sea capaz de detectar personas.

 \subsection{Base de datos}
 Para lograr el entrenamiento de la red neuronal, primeramente se tiene que construir una base de datos, esta base tiene que estar compuesta por imágenes donde aparezcan personas. Posteriormente, comienza un proceso de \say{etiquetado}, en el cual se tiene que señalar donde se encuentra la persona en las diferentes imágenes, este procedimiento se realiza con la aplicación LabelImg, este proceso se observa en la Figura \ref{fig:labeling}.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.25]{imagenes/persona1.png}
	\caption{Proceso de etiquetado para generar los archivos necesarios para el entrenamiento.}
	\source{Elaboración propia}
	\label{fig:labeling}
\end{figure}

Este proceso se tiene que realizar con cada imagen, para así obtener un archivo que especifica la posición de dónde se encuentra la \say{persona} en la imagen. En la Figura \ref{fig:labeling2} se observa la manera en la que se guardan esos datos. De esta manera se obtiene una base de datos que sirve para entrenar la red neruonal YOLO, la cual debe estar compuesta por lo menos con 400 imágenes. 

\clearpage

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{imagenes/persona2.png}
	\caption{Coordenadas obtenidas por el programa LabelImg al etiquetar a un objeto.}
	\source{Elaboración propia}
	\label{fig:labeling2}
\end{figure}

Este procedimiento se puede realizar mas rápido gracias a la base de datos de Google, el cual tiene una gran cantidad de imágenes ya etiquetadas lo que facilita el proceso de realizar un entrenamiento, esto se observa mejor en la Figura \ref{fig:labeling5}. El único inconveniente de esta herramienta es que la base de datos esta en un formato que Darknet no lo reconoce, pero ya existen otras herramientas que permiten convertir a un formato con la cual se puede trabajar.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.2]{imagenes/persona5.png}
	\caption{Base de datos de Google para el entrenamiento de redes neuronales.}
	\source{Elaboración propia}
	\label{fig:labeling5}
	\end{figure}

\subsection{Preparación del ambiente}

Al momento de entrenar una red neuronal se utiliza muchos recursos de la computadora, sobre todo en el apartado del GPU, ya que la mayoría de los cálculos se realizan de mejor manera en esa parte. Esto resulto ser un problema ya que mi computadora no cuenta con una GPU dedicada y los entrenamientos se realizaban de manera muy lenta, por ese motivo se opto por usar Colab, el cual es un servicio de Google que te permite realizar entrenamientos de redes neuronales ya que te deja usar los GPU's de sus servidores.
\\

Colab es un editor de texto online, que te permite escribir tu código y probarlo sin la necesidad de instalar programas en tu computadora, pero será necesarios instalarlos en tu editor online. El primer paso es instalar Darknet, el cual te permite trabajar con YOLO.

\clearpage

Para qué Darknet funcione correctamente necesita diferentes frameworks, en la Figura \ref{fig:labeling42} se puede observa una lista con los frameworks necesarios. Para poder instalarlos se utiliza el comando \say{pip}, el cual es un sistema de gestión de paquetes de Python. La mayoría de estos frameworks ya vienen instalados por defecto en Colab por ser muy utilizados.
 
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona3.png}
	\caption{Frameworks necesarios para que funcione Darknet.}
	\source{Elaboración propia}
	\label{fig:labeling42}
\end{figure}

\subsection{Personalizar una red neuronal}

La red neuronal YOLO y Tiny-Yolo viene por defecto entrenada con varias clases que le permite detectar diferentes objetos, pero ninguna se podía ajustar a las necesidades del proyecto y por eso mismo se tuvo que realizar un entrenamiento con una base de datos propia.

Antes de modificar los paramatros, se decidio usar la Tyin-Yolo debido a que es una red neuronal mas liviana (con menos capas), lo que ocaciones que sea menos exigente cuando se tiene que procesar las detecciones, lo que permite que funcione de mejor manera en mi computadora.

La diferencia de rendimiento se podrá ver de mejor manera en la Tabla \ref{tab:fruta}, el cual da cómo mejor opción Tiny-Yolo teniendo un mejor rendimiento que al usar YOLO. El único problema de usar Tiny-Yolo es que se pierde un poco de precisión al momento de realizar las detecciones.

\begin{table}[h]
\caption{Resultados de una prueba de rendimiento entre YOLO y Tiny-Yolo.}
\begin{center}
%\caption{Resultados de una prueba de rendimiento entre YOLO y Tyni-Yolo.}
\begin{tabular}{| l | c |}
\hline \textbf{Versión de YOLO} & \textbf{FPS} \\ \hline
Tiny-yolo & 7-10  \\
Yolo & 1-3 \\ \hline
\end{tabular}

\label{tab:fruta}
\sources{Elaboración propia.}
\end{center}
\end{table}

Estos resultados demuestran que la mejor opción es trabajar con Tiny-Yolo, por lo cual se modificara el archivo \say{yolov4-tiny.cfg}, en el cual se cambiaran ciertos parámetros para que la red neuronal al momento de entrenar se adapte a los requerimientos del proyecto. los parámetros que se modificaron están señaladas en la Figura \ref{fig:labeling6}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona6.png}
	\caption{Se define el learning rate.}
	\source{Elaboración propia}
	\label{fig:labeling6}
\end{figure}

El dato marcado \textit{learning rate} es el que determina el ritmo de aprendizaje, entre mas bajo sea este valor aumentara el ritmo de aprendizaje pero esto alarga el entrenamiento. Un valor muy bajo no es muy útil ya que no mejoraría el entrenamiento pero si demoraría mas tiempo en terminar y aumenta la probabilidad de que se detenga el entrenamiento por un error.
El siguiente es \textit{max batches}, el que se encarga de limitar el número de pasos máximos que realizará en el entrenamiento. Este número es obtenido mediante una simple fórmula que se observa en la Ecuación \ref{eq:maxb}, pero solo es aplicada cuando se trabajará con 3 o más clases de detección, caso contrario simplemente se tendrá que colocar \say{6000}, como es en este caso. En \textit{step} se tomará el 80\% y 90\% de \say{max batches} respectivamente.

\begin{equation}
\label{eq:maxb}
	max\_batches = \#\operatorname{clases} * 2000
\end{equation}

Otros parametros que se tienen que modificar son los datos marcadsos que aparecen en la Figura \ref{fig:labeling7}, que consiste en definir la cantidad de filtros y especificar cuántas clases tendrá que aprender la red neuronal.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona7.png}
	\caption{Se establece la cantidad de filtros a usarse.}
	\source{Elaboración propia}
	\label{fig:labeling7}
\end{figure}

Para calcular la cantidad de filtros se hará uso de una fórmula simple que se puede apreciar en la Ecuación \ref{eq:clases}, este dato obtenido se tendrá cambiar en todos los filtros que se encuentra en el documento \say{yolov4-tiny.cfg}.

\begin{equation}
	filtros = (\#\operatorname{clases}+5)*3
	\label{eq:clases}
\end{equation}

Con esto se finaliza los cambios en el archivo \say{yolov4-tiny.cfg}, pero aún falta editar otros 2 archivos más el cual uno definirá el nombre de la clase y en el otro se definirán la ubicación de los archivos necesarios para entrenar, la locación de donde se guardara la red entrenada y cuantas clases se usara para entrenar, esto se aprecia en la Figura \ref{fig:labeling45}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona8.png}
	\caption{Se detalla la cantidad de clases y nombres que se usarán para entrenar la red neuronal.}
	\source{Elaboración propia}
	\label{fig:labeling45}
\end{figure}

\subsection{Inicio de entrenamiento}

Para iniciar el entrenamiento se tiene que preparar todos los archivos en el ambiente Colab, primeramente, se tiene que cargar todas las imágenes ya etiquetadas y de ahí se procedería a ejecutar los siguientes comandos que se observan en la Figura \ref{fig:labeling46}, el cual creará unos archivos basados con la cantidad de clases por el cual se entrenara.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona11.png}
	\caption{Comando para generar archivos que guiaran el entrenamiento.}
	\source{Elaboración propia}
	\label{fig:labeling46}
\end{figure}

Una vez teniendo los archivos generados se procede a iniciar el entrenamiento mediante el siguiente comando que aparece en la Figura \ref{fig:labeling47}. La duración de este entrenamiento dependerá de la cantidad de imágenes que se esta usando para realizar el entrenamiento, en este caso el entrenamiento duro aproximadamente 4 horas, pero se repitió 2 veces para mejorar los resultados obtenidos.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona12.png}
	\caption{Comando para iniciar el entrenamiento.}
	\source{Elaboración propia}
	\label{fig:labeling47}
\end{figure}

Al finalizar el entrenamiento ya se obtendrá una red neuronal funcional, capaz de detectar personas. Un resultado de este entrenamiento se observa en la Figura \ref{fig:labeling48}, donde se ven marcadas una cantidad aceptable de personas que aparecen en la imagen, cada recuadro que marca a una personas viene con un numero el cual indica el porcentaje de seguridad de detención realizada por la red neuronal.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona14.png}
	\caption{Resultado del entrenamiento realizado.}
	\source{Elaboración propia}
	\label{fig:labeling48}
\end{figure}

\section{Prueba de rendimiento}

Una vez entrenada la red neuronal se procede a realizar unas diversas pruebas para así poder calcular el rendimiento y sobre todo la precisión de esta red construida. Para estas pruebas se está usando la documentación que proporciona la pagina de desarrolladores de Google, donde se detalla la manera en la que se tiene que realizar estas pruebas para calcular la precision.

Para estas pruebas se está usando un video de vigilancia que fue proporcionado por el supermercado Makro, la posición de la cámara permite capturar bien la fila que se genera en el supermercado. Este video será analizado por la red neuronal y así calcular cuantas personas fueron detectadas para así realizar una comprobación que permita confirmar si la cantidad de personas detectadas es la correcta.  

Una vez procesado el video por la red neuronal se extrajo 44 imágenes, con estas imágenes se procedió a realizar el análisis el cual permitiría medir la precisión de esta red neuronal. Para ellos las diferentes detecciones se dividió en 3 diferentes categorías, estas categorías son: verdadero positivo (VP), falso positivo (FP) y falso negativo (FN).



\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/VPFPFN.png}
	\caption{Pantalla principal de la aplicación NeoVision.}
	\source{Elaboración propia}
	\label{fig:labeling30}
\end{figure}

\section{Diseño de la interfaz}
Para el diseño de la interfaz se utilizo la herramienta Balsamiq Wireframes, el cual permite planificar cómo se vera la interfaz de alguna aplicación. Con esta herramienta se diseño 2 pantallas para así determinar el diseño que tendrá la aplicación.

\subsection{Detección de personas}

Esta es la pantalla principal de la aplicación, donde se  indica la información de cuántas personas están siendo detectadas en ese momento, de igual manera se muestra en tiempo real el video obtenido por la cámara de seguridad. Otra información importante que se indica en la interfaz es el limite de detección, el cual ayuda a visualizar mejor los datos de esta pantalla, esto se apreciará mejor en la Figura \ref{fig:labeling30}. 

\clearpage
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/imagen1.png}
	\caption{Pantalla principal de la aplicación NeoVision.}
	\source{Elaboración propia}
	\label{fig:labeling30}
\end{figure}

\subsection{Pantalla de alerta}

Esto es una pantalla de alerta que solo aparecerá cuando se pase el limite de tiempo de espera de una persona en la fila del supermercado. Esta pantalla tendrá una imagen de alerta para así poder captar la atención de las personas y se aconsejara abrir una nueva caja para poder acelerar el proceso de atención, el diseño de esta pantalla se puede ver en la Figura \ref{fig:labeling31}.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/imagen2.png}
	\caption{Mockup de la pantalla de alerta.}
	\source{Elaboración propia}
	\label{fig:labeling31}
\end{figure}

\section{Diagrama de flujo}
En este apartado se mostrará un diagrama de flujo en el que se representa los principales procesos de este proyecto, cuáles son detectar a personas y dependiendo del tiempo de espera notificar con una alerta, este diagrama se observa en la Figura \ref{fig:labeling33}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=1]{imagenes/NeoVision3.png}
	\caption{Diagrama de flujo explicativo sobre la función de la aplicación NeoVision.}
	\source{Elaboración propia}
	\label{fig:labeling33}
\end{figure}

\clearpage
\section{Diagrama C4Model}
En este apartado se dará conocer un esquema siguiendo el modelo C4Model, el cual se va explicando de manera general hasta llegar a lo más específico, empezando por el contexto de la situación, sus contenedores, componentes y por último un diagrama de todas las clases.

\subsection{Contexto}
En este apartado se observará las diferentes interacciones que tiene la aplicación, esto se apreciará mejor en la Figura \ref{fig:labeling32}.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/contenido2.png}
	\caption{Diagrama de contexto que representa las interacciones del sistema.}
	\source{Elaboración propia}
	\label{fig:labeling32}
\end{figure}
Con este diagrama se puede mostrar cuáles son las interacciones que realiza la aplicación, como ser el personal de sistemas es el que inicia la aplicación y si es necesario configura ciertos parámetros, por otra parte, la aplicación interactúa con el personal de seguridad mediante avisos que ejecutara cuando el tiempo de espera de una persona sobrepase el tiempo configurado.
\subsection{Contenedores}

En esta sección se observa más a detalle los sistemas usados para que la aplicación funcione, esto se ve en la Figura \ref{fig:labeling34}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/contenedor3.png}
	\caption{Diagrama de contenedores que representa las diferentes funciones de los sistemas.}
	\source{Elaboración propia}
	\label{fig:labeling34}
\end{figure}

Con este diagrama conocemos cuáles son las funciones de los diferentes sistemas que tiene la aplicación, por ejemplo, Darknet es el encargado de realizar las detecciones en las imágenes que le envía la aplicación principal. Por otra parte, Deepsort es el que recibe los resultados de Darknet y este aplica un ID único a cada detección, esta información es recibida por NeoVision, la cual le permite realizar los cálculos para determinar si es necesario abrir una nueva caja. 

\section{Descripción de la aplicación}



Para comenzar el desarrollo de la aplicación primeramente se tiene que crear una ambiente virtual de Python en la computadora, ya que se necesita instalar ciertos paquetes que podrían entrar en conflicto con algunas aplicaciones ya instaladas y también genera un mayor orden.
La herramienta ideal para realizar esto es VirtualenvWrapper, ya que es fácil de instalar y sobre todo es simple de ingresar al ambiente virtual, sobre todo cuando se compara con otras herramientas. Esta diferencia aprecia mejor en la Figura \ref{fig:labeling9}.

\clearpage
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona15.png}
	\caption{Diferencia entre iniciar un ambiente virtual de Python entre VirtualWrapper y Virtualenv.}
	\source{Elaboración propia}
	\label{fig:labeling9}
\end{figure}


Con el ambiente virtual se procede a instalar los diversos paquetes necesarios, donde los principales son Tensorflow y OpenCV. Teniendo estos recursos instalados, se procede a convertir la red neuronal entrenada que se encuentra en un formato \say{.weights}, a un formato que Tensorflow soporte. Para ello usaremos un código disponible hecho por la misma comunidad, que está hecho en Python, en la Figura \ref{fig:labeling10} se muestra el comando para convertir la red.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{imagenes/convertir_yolo.png}
	\caption{Comando para convertir la red neuronal.}
	\source{Elaboración propia}
	\label{fig:labeling10}
\end{figure}

 Para realizar la aplicación se hará uso del editor PyCharm, porque es gratis y tiene una interfaz intuitiva al momento de usarlo.
 El primer paso al comenzar la aplicación es comenzar a importar todos los paquetes que se necesitará para que funcione, la manera en la que se importa los paquetes se podrá observar en el siguiente Código \ref{23}.
 \vspace{5mm}

\begin{lstlisting}[language=Python,caption={Manera en la que se importan los diferentes paquetes al programa.},captionpos=b,label=23]
	import os 
	import subprocess
	from datatime import datetime
	import tensorflow as tf
	import time
\end{lstlisting}
\vspace{5mm}

Con todo esto ya se puede dar comienzo para que la aplicación pueda leer los videos mediante OpenCV y así iniciar el detector para que encuentre las personas de un video.

\subsection{Agregar el tracker a la detección}

Por sí solas la detección que se puede hacer no brinda la información suficiente como para contar las detecciones o corregir errores que se pueden generar. Uno de estos errores es que como en un video hay objetos en movimiento simplemente puede desaparecer las detecciones, debido a que por el movimiento no se llega a reconocer al objeto, esto se puede ver en la Figura \ref{fig:labeling12}.
\clearpage
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{imagenes/deteccionvstracker.png}
	\caption{Comparación entre usar solo la detección y usar tracker con detección.}
	\source{Elaboración propia.}
	\label{fig:labeling12}
\end{figure}

Cómo se ve en la figura anterior, no se marca todos los objetos en el lado que no utiliza \textit{tracker}, ya que justo en ese \textit{frame} no lo identifica bien y se pierde. Pero en otra parte del mismo video se ve que en la Figura \ref{fig:labeling13}, desaparece el objeto detectado, por otra parte el que utiliza el \textit{tracker} no pierde ninguna detección.

\vspace{5mm}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{imagenes/deteccionvstracker2.png}
	\caption{Error al solo usar la detección en un proyecto.}
	\source{Elaboración propia.}
	\label{fig:labeling13}
\end{figure}
\vspace{5mm}

Pero el problema mas importante es que cuando una persona se sale del enfoque de la cámara o es cubierto por algún objeto, la detección se pierde y cuando vuelve a aparecer la app lo detecta como si fuera una nueva persona. 
Esto se podrá solucionar incorporando a la detección un \textit{tracker}, mediante esto se podrá generar ID a cada detección y con eso se podrá diferenciar entre detecciones, ya que todos tendrán un identificador que permitiría contar a las personas detectadas.
El \textit{tracker} a utilizar es DeepSort, el cual es de uso libre, para que funcione correctamente se tiene que usar una red pre-entrenada que ayuda al proceso del rastreo.
\clearpage

\subsection{Agregar contador y límite de detección}

Para que se pueda contar la cantidad de personas detectas se usara una función de Deepsort el cual genera una lista de las detecciones y mediante OpenCV se podrá mostrar en la pantalla del mismo video como se ve en la Figura \ref{fig:labeling14}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{imagenes/persona19.png}
	\caption{Contador de personas en un video.}
	\source{Elaboración propia}
	\label{fig:labeling14}
\end{figure}

El límite se encargará de reiniciar el contador y los cálculos de tiempo máximo de espera de un cliente en una fila. En la Figura \ref{fig:labeling35} se aprecia cómo se muestra el límite creado, esta línea es solo una representación visual, ya que las coordenadas de la línea son los importantes al momento de trabajar en la aplicación.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona20.png}
	\caption{Línea que limita las detecciones en un video.}
	\source{Elaboración propia}
	\label{fig:labeling35}
\end{figure}

\clearpage
Esto se logra gracias a OpenCV, ya que con él se dibujara una línea, el cual representa el límite para la detección y cuando un objeto cruce la línea ya no será tomando en cuenta. Esto funciona porque por cada detección genera unas coordenadas de la posición del objeto, teniendo esto se sabe cuándo cruza la línea.

\subsection{Alarma al superar el tiempo máximo}

Este apartado se encarga de informar cuando se sobrepase el tiempo máximo de espera definido, para saber esto se creó una lista donde se registra la hora en la que se detectó la persona, en la Figura \ref{fig:labeling16} se observa como está compuesta la lista, la cual guarda datos necesarios para realizar la alarma y el límite de detección.

\vspace{5mm}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona21.png}
	\caption{Lista que guarda datos cada vez que se realiza una nueva detección.}
	\source{Elaboración propia}
	\label{fig:labeling16}
\end{figure}
\vspace{5mm}

Teniendo esta lista podemos registrar la hora en la que fue detectado una persona y con ello al tener una lista donde se detectaron 3 personas nos permite calcular un tiempo promedio de espera y con ese dato se podrá comparar con el tiempo máximo de espera.
Si este tiempo promedio de espera es mayor que el tiempo máximo, se procederá a notificar mediante un \say{popup} que el cliente está esperando mucho y que se recomienda abrir una nueva caja.
\\

Otra manera en la que se puede activar la alarma es cuando por un determinado tiempo ni una persona llegó a cruzar el límite definido, de igual manera que en el anterior caso se activará un \say{popup} notificando un problema al encargado para determinar si lo ve necesario abrir una caja o no. En la Figura \ref{fig:labeling17} se observa el diseño del \say{popup} y el mensaje que da.

\vspace{5mm}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.45]{imagenes/persona22.png}
	\caption{Alerta popup que se activa cuando se alcanza el tiempo máximo de espera.}
	\source{Elaboración propia}
	\label{fig:labeling17}
\end{figure}


\subsection{Crear una base de datos}

Con este apartado se está utilizando una base datos para registrar la hora exacta cuando salte una alarma. Esto sirve para poder ver cuándo son las horas críticas y así buscar una solución que mejoraría la atención.
Para la base de datos se usa Mongodb, el cual te permite guardar los datos tanto de manera local como en la nube y es una herramienta gratuita.

En este caso como aplicación fue probada en un MacBook Pro 2014, la instalación de Mongodb variará en una máquina Windows. Simplemente para instalar la base de datos se tendrá que correr el siguiente comando que aparece en la Figura \ref{fig:labeling18}, estos comandos se tienen que hacer correr en la terminal.

\vspace{5mm}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.55]{imagenes/mongodc.png}
	\caption{Comando de instalación en Mac de MongoDB.}
	\source{Elaboración propia}
	\label{fig:labeling18}
\end{figure}

El dato que se guardará es la hora en la que la alarma se active, esto se logra con los siguientes comandos que aparecen en el siguiente Código \ref{24}, estos tienen que estar dentro de la aplicación creada.
\vspace{5mm}

 \begin{lstlisting}[language=Python,caption={Comando para guardar información en la base de datos.},captionpos=b,label=24]
post = {"data": datetime.now()}
alarms = db.alarms
alarms.insert_one(post)
DETECTION_EVENTS.clear()
\end{lstlisting}
\vspace{5mm}

En este caso la información de la base de datos se almacena de manera local, lo que significa que cada vez que se inicie la aplicación se tendrá que activar MongoDB, esto se logra con el siguiente comando que aparece en la Figura \ref{fig:labeling20}, de la misma manera se tendrá que desactivar cuando ya no se utilice la aplicación. 

\vspace{5mm}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona25.png}
	\caption{Comandos para iniciar y detener la base de datos.}
	\source{Elaboración propia}
	\label{fig:labeling20}
\end{figure}


\section{Conclusiones del capitulo III}

En el presente capítulo se explico el motivo de la elección de la red neuronal, la cual es YOLO. Teniendo echa la elección se decidio realizar pruebas para saber que version de YOLO se adapta mejor al proyecto y con esos resultados se opto por Tiny-Yolo.
\\
Con la red neuronal seleccionada se procedió a realizar el respectivo entrenamiento para que pueda detectar a personas y así poder utilizar la información obtenida para calcular el tiempo promedio de espera de las personas que están esperando en una fila. Posteriormente, se explico el funcionamiento de la aplicación y cómo el usuario puede interactuar con la interfaz.

   
















