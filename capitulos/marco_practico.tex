\section{Elección de una red neuronal}
Para la elección de la red neuronal se tomara en cuenta un estudio realizado por el equipo de YOLO, (\cite{persona}), que mediante unas pruebas realizadas con un mismo \textit{hardware}, para así determinar cual es el que posee un mejor rendimiento, el resultado de estas pruebas se puede observar en la figura \ref{fig:labeling3}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{imagenes/persona9.png}
	\caption{Comparación de YOLO y otros detectores de objetos de última generación.}
	\source{YOLOv4: Optimal Speed and Accuracy of Object Detection. (2020)}
	\label{fig:labeling3}
\end{figure}

Las pruebas fueron realizadas con la base de datos \say{coco}, que recopila una gran base de datos que facilitan la detección de diferentes objetos. Con estos resultados nos muestran que la red neuronal YOLO es la mejor opción, ya que detecta los objetos con mayor velocidad y con un mayor porcentaje de acierto. 

\section{Entrenamiento de la red neuronal}
En este capítulo se desarrollaran los diferentes pasos para lograr entrenar una red neuronal, para que se capaz de detectar personas ya sea en imágenes y en videos tanto grabados como en tiempo real.

 \subsection{Base de datos}
Uno de los primeros pasos para entrenar una red neuronal es tener una base de datos, el cual esta compuesto por imágenes (donde aparezca el objeto a detectar) y un archivo que indique la posición del objeto a detectar en la imagen.
\\ Para ello se consiguió 400 imágenes donde aparezcan personas y con ellos realizar un procedimiento de etiquetado, en la figura \ref{fig:labeling} se observa este proceso. Esto se logra mediante el programa LabelImg que te permite etiquetar la posición de una persona en una imagen.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.25]{imagenes/persona1.png}
	\caption{Proceso de etiquetado para generar los archivos necesarios para el entrenamiento.}
	\source{Elaboración propia}
	\label{fig:labeling}
\end{figure}

Este proceso se realiza con cada imagen, para así obtener un archivo que especifica la posición de dónde se encuentra la \say{persona} en este caso. En la figura \ref{fig:labeling2} se observa la manera en la que se guardan esos datos. 

\clearpage

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{imagenes/persona2.png}
	\caption{Coordenadas obtenidas por el programa LabelImg al etiquetar a un objeto.}
	\source{Elaboración propia}
	\label{fig:labeling2}
\end{figure}

Esta recopilación de datos se puede realizar mas fácil gracias a Google, facilitándo esta tarea permitiéndote usar su propia base de datos donde aproximadamente tiene cuatro millones de imágenes, figura \ref{fig:labeling5}, el cual ya fueron etiquetados varios objetos como ser personas, autos, aviones, relojes y otros mas.



\begin{figure}[h]
	\centering
	\includegraphics[scale=0.2]{imagenes/persona5.png}
	\caption{Base de datos de Google para el entrenamiento de redes neuronales.}
	\source{Elaboración propia}
	\label{fig:labeling5}
	\end{figure}

\subsection{Preparación del ambiente}

Para entrenar una red neuronal se necesita muchos recursos en una computadora sobre todo en la área del GPU, ya que todos los cálculos que realiza son procesados de manera más efectiva en esa área. 
Por ese motivo se decidió usar un servicio de Google que es Colab, el cual te permite conectarse a sus servidores y poder entrenar la red de forma gratuita. 
\\

Colab es un editor de Python online, que te permite escribir tu código y probarlo sin instalar programas en tu computadora, pero será necesarios instalarlos en tu editor online. EL primer paso es instalar Darknet, el cual te permite trabajar con YOLO.

\clearpage

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona3.png}
	\caption{Frameworks necesarios para que funcione Darknet.}
	\source{Elaboración propia}
	\label{fig:labeling4}
\end{figure}

 Como se observa en la figura \ref{fig:labeling4}, Darknet necesita diferentes frameworks para que funcione. Estos se instalan con la ayuda del comando \textit{pip}, el cual es un sistema de gestión de paquetes de Python. Se procederá a instalar estos paquetes mediante el comando que se aprecia en la figura, ya que estos requisitos están guardados en un archivo \say{.txt} en el mismo Darknet.
 
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona4.png}
	\caption{Comando de instalación de paquetes.}
	\source{Elaboración propia}
	\label{fig:labeling4}
\end{figure}


\subsection{Personalizar una red neuronal}

En esta etapa se tiene que modificar diferentes archivos para que la red pueda detectar a personas. Estos archivos por modificar son los parámetros que definen la red neuronal, en Darknet existen 2 redes principales que son Yolo y Tiny-Yolo. La gran diferencia entre estos son la cantidad de capas que poseen, esto llega a afectar el rendimiento en una detección. 
\vspace{5mm}

Por eso mismo se decidió usar Tiny-Yolo, ya que con pruebas realizadas dio un mejor rendimiento en el apartado de fotógrafas por segundo (fps), al momento de trabajar con videos, esto es muy importante ya que la detección se realizara en tiempo real. Los resultados de la prueba se apreciara mejor en la figura \ref{fig:labeling4}.

\clearpage

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona10.png}
	\caption{Comparación de rendimiento entre diferentes redes neuronales YOLO.}
	\source{Elaboración propia}
	\label{fig:labeling4}
\end{figure}

Con estos resultados se modificara el archivo \say{yolov4-tiny.cfg}, y los datos a cambiar dependerán mayormente a la cantidad de clases al cual se entrenara la red neuronal, estos datos son los que están marcados en la figura \ref{fig:labeling6}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona6.png}
	\caption{Datos a modificar en yolov4-tiny.cfg.}
	\source{Elaboración propia}
	\label{fig:labeling6}
\end{figure}

El dato marcado \textit{learning rate} es el que determina el ritmo de aprendizaje, entre mas bajo sea podrá aprender mas pero  eso alarga el periodo de entrenamiento, en este apartado no hay que exagerar ya que un dato muy bajo simplemente lo hará mas lento y no ayudara en el entrenamiento.

El siguiente es \textit{max batches}, el que encarga de limitar el numero de pasos máximo que realizara en el entrenamiento. Este numero es obtenido mediante una simple formula, pero solo es aplicada cuando se trabajara con 3 o mas clases de detección, caso contrario simplemente se tendrá que colocar \say{6000}. En \textit{step} se tomara el 80\% y 90\% de \say{max batches} respectivamente.

\begin{equation}
	max\_batches = \#\operatorname{clases} * 2000
\end{equation}

Los otros datos por modificar son los que se aprecian en la figura \ref{fig:labeling7}, que consiste la cantidad de filtros y especificar cuántas clases tendrá que aprender la red neuronal.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona7.png}
	\caption{Se establece la cantidad de filtros a usarse.}
	\source{Elaboración propia}
	\label{fig:labeling7}
\end{figure}

Para calcular la cantidad de filtros se tendrá que usar otra formula simple, este dato obtenido se tendrá cambiar en todos los filtros que se encuentra en el documento \say{yolov4-tiny.cfg}.

\begin{equation}
	filtros = (\#\operatorname{clases}+5)*3
	\label{eq:persona}
\end{equation}

Con eso finaliza los cambios en el archivo \say{yolov4-tiny.cfg}, pero aun falta editar otros 2 archivos mas el cual uno definirá el nombre de la clase y en el otro se definirán la ubicación de los archivos necesarios para entrenar y la locación de donde se guardara la red entrenada, esto se aprecia en la figura .

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona8.png}
	\caption{Se especifica el nombre y la cantidad de las clases.}
	\source{Elaboración propia}
	\label{fig:labeling8}
\end{figure}

\subsection{Inicio de entrenamiento}

Para esta etapa ya se tiene todo lo necesario para iniciar el entrenamiento dentro del ambiente de Google Colab, el cual facilita este procedimiento. Para comenzar se tuvo que correr el comando que aparece en la figura , el cual creara unos archivos basados con la cantidad de clases por el cual vamos a entrenar y la cantidad de imágenes con el cual entrenara.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona11.png}
	\caption{Comando para generar archivos que guiaran el entrenamiento.}
	\source{Elaboración propia}
	\label{fig:labeling8}
\end{figure}

Con todo esto solo queda correr otro comando el cual iniciará el entrenamiento, este se podrá ver en la figura . Este entrenamiento normalmente lleva entre 2 a 3 horas aproximadamente.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona12.png}
	\caption{Comando para iniciar el entrenamiento.}
	\source{Elaboración propia}
	\label{fig:labeling8}
\end{figure}

Al terminar el entrenamiento ya se tendrá una red neuronal funcional, capaz de detectar personas. un resultado del entrenamiento se observa en la figura . dónde se ven marcadas una cantidad aceptable de personas que aparecen en la imagen.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{imagenes/persona14.png}
	\caption{Resultado del entrenamiento realizado.}
	\source{Elaboración propia}
	\label{fig:labeling8}
\end{figure}

\section{Diseño de la interfaz}
Para el desarrollo de interfaces se utilizo la herramienta Balsamiq Wireframes con 2 pantallas principales, el cual son: detección de personas y ventana de alarma. 
\subsection{Detección de personas}

Esta es la pantalla principal de la aplicación, en el cual se observa las detecciones que se esta realizando, el limite de detección y la cantidad de personas que aparecen en el video, esto se apreciara mejor en la figura \ref{fig:labeling30}.
\clearpage
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{imagenes/imagen1.png}
	\caption{Pantalla principal de la aplicación NeoVision.}
	\source{Elaboración propia}
	\label{fig:labeling30}
\end{figure}

\subsection{Pantalla de alerta}

Esta pantalla solo aparecerá cuando la alarma se active, lo que significa, es que se llego a sobrepasar el tiempo máximo de espera de una persona en la fila, el diseño de esta pantalla se puede ver en la figura \ref{fig:labeling31}.

\clearpage
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/imagen2.png}
	\caption{Mockup de la pantalla de alerta.}
	\source{Elaboración propia}
	\label{fig:labeling31}
\end{figure}

\section{Diagrama de flujo}
En este apartado se mostrara un diagrama de flujo en el que se representa los principales procesos de este proyecto, cuales son detectar a personas y dependiendo del tiempo de espera notificar con una alerta, este diagrama se observa en la figura \ref{fig:labeling33}.
\clearpage
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{imagenes/NeoVision.png}
	\caption{Diagrama de flujo explicativo sobre la función de la aplicación NeoVision.}
	\source{Elaboración propia}
	\label{fig:labeling33}
\end{figure}

\section{Diagrama C4Model}
En este apartado se dará conocer un esquema siguiendo el modelo C4Model, el cual se va explicando de manera general hasta llegar a lo mas especifico, empezando por el contexto de la situación, sus contenedores, componentes y por ultimo un diagrama de todas las clases.
\subsection{Contexto}
En este apartado se observara las diferentes interacciones que tiene la aplicación, esto se apreciara mejor en la figura \ref{fig:labeling32}.

\clearpage
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/contexto.png}
	\caption{Diagrama de contexto que representa las interacciones del sistema.}
	\source{Elaboración propia}
	\label{fig:labeling32}
\end{figure}

\subsection{Contenedores}

En esta sección se observa mas a detalle los sistemas usados para que la aplicación funcione, esto se ve en la figura \ref{fig:labeling34}.
\clearpage
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/contenedor.png}
	\caption{.}
	\source{Elaboración propia}
	\label{fig:labeling34}
\end{figure}


\section{Descripción de la aplicación}



Para comenzar el desarrollo de la aplicación primeramente se tiene que crear una ambiente virtual de python en la computadora, ya que se necesita instalar ciertos paquetes que podrían entrar en conflicto con algunas aplicaciones ya instaladas y también genera un mayor orden.
La herramienta ideal para realizar esto es VirtualenvWrapper, ya que es fácil de instalar y sobre todo es simple de ingresar al ambiente virtual, sobre todo cuando se compara con otras herramientas. Esta diferencia aprecia mejor en la figura \ref{fig:labeling9}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona15.png}
	\caption{Diferencia entre iniciar un ambiente virtual de Python entre VirtualWrapper y Virtualenv.}
	\source{Elaboración propia}
	\label{fig:labeling9}
\end{figure}



Con el ambiente virtual se procede a instalar los diversos paquetes necesarios, donde los principales son Tensorflow y OpenCV. Teniendo estos recursos instalados, se tendrá que convertir la red neuronal entrenada a un formato que Tensorflow soporte. Para ello usaremos un código disponible hecho por la misma comunidad, que esta echo en python, en la figura \ref{fig:labeling10} se muestra el comando para convertir la red.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona16.png}
	\caption{Comando para convertir la red neuronal.}
	\source{Elaboración propia}
	\label{fig:labeling10}
\end{figure}

 Para realizar la aplicación se hará uso del editor PyCharm, porque es gratis y tiene una interfaz intuitiva al momento de usarlo.
 El primer paso al comenzar la aplicación es comenzar a importar todos los paquetes que se necesitara para que funcione, la manera en la que se importa los paquetes esta en la figura \ref{fig:labeling11}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona16.png}
	\caption{Manera en la que se importa los paquetes en un documento Python.}
	\source{Elaboración propia}
	\label{fig:labeling11}
\end{figure}

Con todo esto ya se pude dar comienzo para que la aplicación pueda leer los videos mediante OpenCV y así iniciar el detector para que encuentre las personas de un video.

\subsection{Agregar el tracker a la detección}

Por sí solas la detección que se puede hacer no brinda la información suficiente como para contar las detecciones o corregir errores que se pueden generar. Uno de estos errores es que como en un video hay objetos en movimiento simplemente puede desaparecer las detecciones, debido a que por el movimiento no se llega a reconocer al objeto, esto se puede ver en la figura \ref{fig:labeling12}

\clearpage

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona17.png}
	\caption{Comparación entre usar solo la detección y usar tracker con detección.}
	\source{Rokas Balsys.}
	\label{fig:labeling12}
\end{figure}

Cómo se ve en la figura anterior, no se marca todos los objetos en el lado que no utiliza \textit{tracker}, ya que justo en ese \textit{frame} no lo identifica bien y se pierde. Pero en otra parte del mismo video se ve que en la figura \ref{fig:labeling13} se marca otro objeto pero desaparece uno, por otra parte el que utiliza el \textit{tracker} no pierde ninguna detección.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona18.png}
	\caption{Error al solo usar la detección en un proyecto.}
	\source{Rokas Balsys.}
	\label{fig:labeling13}
\end{figure}

\clearpage

Pero el problema mas importante es que cuando una persona se sale del enfoque de la cámara o es cubierto por algún objeto, la detección se pierde y cuando vuelve a aparecer la app lo detecta como si fuera una nueva persona. 
Esto se podrá solucionar incorporando a la detección un \textit{tracker}, mediante esto se podrá generar ID a cada detección y con eso se podrá diferenciar entre detecciones ya que todos tendrán un identificador que permitiría contar a las personas detectadas.
El \textit{tracker} a utilizar es DeepSort, el cual es de uso libre, para que funcione correctamente se tiene que usar una red pre-entrenada que ayuda al proceso del rastreo.

\subsection{Agregar contador y limite de detección}

Para que se pueda contar la cantidad de personas detectas se usara una función de Deepsort el cual genera una lista de la detecciones y mediante OpenCV se podrá mostrar en la pantalla del mismo video como se ve en la figura \ref{fig:labeling14}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona19.png}
	\caption{Contador de personas en un video.}
	\source{Elaboración propia}
	\label{fig:labeling14}
\end{figure}

El limite se encargara de reiniciar el contador y los cálculos de tiempo máximo de espera de un cliente en una fila. En la figura \ref{fig:labeling35} se aprecia cómo se muestra el limite creado, esta linea es solo una representación visual, ya que las coordenadas de la linea son los importantes al momento de trabajar en la aplicación.

\clearpage

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona20.png}
	\caption{Linea que limita las detecciones en un video.}
	\source{Elaboración propia}
	\label{fig:labeling35}
\end{figure}

Esto se logra gracias a OpenCV, ya que con él se dibujara una linea, el cual representa el limite para la detección y cuando un objeto cruce la linea ya no será tomando en cuenta. Esto funciona porque por cada detección genera unas coordenadas de la posición del objeto, teniendo esto se sabe cuándo cruza la linea.

\subsection{Alarma al superar el tiempo máximo}

Este apartado se encarga de informar cuando se sobrepase el tiempo máximo de espera definido, para saber esto se creo una lista donde se registra la hora en la que se detecto la persona, en la figura \ref{fig:labeling16} se observa como esta compuesta la lista el cual guarda datos necesarios para realizar la alarma y el limite de detección.

\clearpage

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona21.png}
	\caption{Lista que guarda datos cada vez que se realiza una nueva detección.}
	\source{Elaboración propia}
	\label{fig:labeling16}
\end{figure}

Teniendo esta lista podemos registrar la hora en la que fue detectado una persona y con ello al tener una lista donde se detectaron 3 personas nos permite calcular un tiempo promedio de espera y con ese dato se podrá comparar con el tiempo máximo de espera.
Si este tiempo promedio de espera es mayor que el tiempo máximo, se procederá a notificar mediante un \say{popup} que el cliente esta esperando mucho y que se recomienda abrir una nueva caja.
\\

Otra manera en la que se puede activar la alarma es cuando por un determinado tiempo ni una persona llego a cruzar el limite definido, de igual manera que en el anterior caso se activara un \say{popup} notificando un problema al encargado para determinar si lo ve necesario abrir una caja o no. En la figura \ref{fig:labeling17} se observa el diseño del \say{popup} y el mensaje que da.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona22.png}
	\caption{Alerta popup que se activa cuando se alcanza el tiempo máximo de espera.}
	\source{Elaboración propia}
	\label{fig:labeling17}
\end{figure}

\clearpage

\subsection{Crear una base de datos}

Con este apartado se esta utilizando una base datos para registrar la hora exacta cuando salte una alarma. Esto sirve para poder ver cuándo son las horas criticas y así buscar una solución que mejoraría la atención.
Para la base de datos se usa Mongodb, el cual te permite guardar los datos tanto de manera local como en la nube y es una herramienta gratuita.

En este caso como aplicación fue probada en un MacBook Pro 2014, la instalación de Mongodb variara en una maquina Windows. Simplemente para instalar la base de datos se tendrá que correr el siguiente comando que aparece en la figura \ref{fig:labeling18}, estos comandos se tienen que hacer correr en la terminal.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.55]{imagenes/persona23.png}
	\caption{Comando de instalación en Mac de MongoDb.}
	\source{Elaboración propia}
	\label{fig:labeling18}
\end{figure}

El dato que se guardara es la hora en la que la alarma se active, esto se logra con los siguientes comandos que aparecen en la figura \ref{fig:labeling19}, estos tienen que estar dentro de la aplicación creada.
 
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona24.png}
	\caption{Comando para guardar información en la base de datos.}
	\source{Elaboración propia}
	\label{fig:labeling19}
\end{figure}

En este caso la información de la base de datos se almacena de manera local, lo que significa que cada vez que se inicie la aplicación se tendrá que activar Mongodb, esto se logra con el siguiente comando que aparece en la figura \ref{fig:labeling20}, de la misma manera se tendrá que desactivar cuando ya no se utilice la aplicación. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{imagenes/persona25.png}
	\caption{Comandos para iniciar y detener la base de datos.}
	\source{Elaboración propia}
	\label{fig:labeling20}
\end{figure}


\section{Funcionamiento de la aplicación}

En este apartado se explicara el funcionamiento de la aplicación, que permitirá poder obtener datos en tiempo real de cuanto una persona en promedio espera hasta ser atendido en la caja.

\subsection{Proceso de iniciar la aplicación}

Para que la aplicación funcione se tiene que correr mediante terminar, utilizando el siguiente comando que aparece en la figura , el comando  correrá el código escrito y se agregan ciertos parámetros que necesita Darknet, el cual definirán el funcionamiento, este comando se observa en la figura \ref{fig:labeling15}.

\begin{figure}[h]
	\centering
	\includegraphics[width=150mm, height=45mm]{imagenes/persona26.png}
	\caption{Comando para que funcione la aplicación, con los parámetros necesarios.}
	\source{Elaboración propia}
	\label{fig:labeling15}
\end{figure}

Estos parámetros definen con qué tipo de video se trabajara, si será un video local, usar una cámara convencional o usar una cámara IP. Otro parámetro importante es definir si los resultados del análisis se guardara en un video.	

\subsection{Proceso de detección y calculo de tiempo de espera promedio}

Cuando la aplicación ya esta iniciada comenzara a realizar la detección en cada Frame del video esperando detectar alguna persona. 
Ahora cuando llega a detectar una persona guardara los siguientes datos: la hora en la que fue detectada, el numero de detección, la posición del objeto detectado.
\vspace{5mm}

Paralela a la acción anterior también comienza a ejecutarse continuamente 2 funciones que calculara el tiempo promedio de espera de un cliente.
Una función ira calculando el tiempo dependiendo de la cantidad de personas que están haciendo fila, pero el otro se encarga de calcular el tiempo en el que una persona tarda en cruzar el limite definido.
\clearpage

Los cálculos de estas funciones serán reincidas cada vez que salte la alarma o cuando sea atendido una persona.
La alarma suena cada vez que se supere el tiempo máximo de espera, el cual se define al comienzo de la aplicación. 
\vspace{5mm}

Al sonar la alarma se inician 2 procesos importantes, el primero se encargara de generar un \say{popup} con un mensaje avisando que es recomendable abrir una nueva caja. Por otra parte, la otra función se encarga de registrar de la hora en la que se activo la alarma, para así tener un registro para observar cuales son los periodos del día con más problemas en atender al cliente. Con esa información se puede buscar una solución permanente que mejore la experiencia del cliente al tener menos tiempo de espera.

























